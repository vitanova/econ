{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected character after line continuation character (<ipython-input-4-db4d48b699bf>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-4-db4d48b699bf>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    from textwra\\p import dedent\u001b[0m\n\u001b[1;37m                                ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m unexpected character after line continuation character\n"
     ]
    }
   ],
   "source": [
    "from textwra\\p import dedent\n",
    "import numpy as np\n",
    "from numpy import dot\n",
    "from scipy.linalg import solve\n",
    "from quantecon.matrix_eqn import solve_discrete_riccati\n",
    "\n",
    "class LQ(object):\n",
    "    r\"\"\"\n",
    "    this class if for analyzing linear quadratic optimal control\n",
    "    problems of either the infinite horizon form\n",
    "        \n",
    "        min E sum_{t=0}^{\\infty} beta^t r{x_t, u_t}\n",
    "        \n",
    "    with\n",
    "    \n",
    "        r{x_t, u_t} :=x_t' R x_t +u_t' Q u_t +2 u_t' N x_t\n",
    "    \n",
    "    or the finite horizon form\n",
    "    \n",
    "        min E sum_{t=0}^{T-1} beta^t r{x_t, u_t} +beta^T x_T' R_f x_T\n",
    "    \n",
    "    both are minimized subject to the law of motion\n",
    "    \n",
    "        x_{t+1} =A x_t +B u_t +C w_{t+1}\n",
    "        \n",
    "    here x is n x1, u is k x 1, w is j x 1 and the matrices are\n",
    "    conformable for these dimensions. the sequence {w_t} is assumed to\n",
    "    be while noice, with zero mean and E w_t w_t =I, the j x j\n",
    "    identity.\n",
    "    \n",
    "    if C is not supplied as a parameter, the model is assumed to be\n",
    "    deterministic (and C is set to a zero matrix of appropriate\n",
    "    dimension)\n",
    "    \n",
    "    for this model, the time t value (i.e., cost-to-go) function V_t\n",
    "    takes the form\n",
    "    \n",
    "        x' P_T x + d_T\n",
    "        \n",
    "    and the optimal policy is of the form u_T=-F_T x_T. In\n",
    "    the infinite horizon case, V, P, d and F are all stationary.\n",
    "    \n",
    "    parameters\n",
    "    ----------\n",
    "    Q: array_like(float)\n",
    "        Q is the payoff(or cost) matrix that corresponds with the\n",
    "        control variable u and is k x k. should be symmetric and\n",
    "        nonnegative definite\n",
    "    R: array_like(float)\n",
    "        R is the payoff(or cost) matrix that corresponds with the\n",
    "        state variable x and is n x n. should be symmetric and\n",
    "        non-negative definite\n",
    "    N: array_like(float)\n",
    "        N is the cross product term in the payoff, as above. it should\n",
    "        be n x n\n",
    "    A: array_like(float)\n",
    "        A is part of the state transition as described above. it should\n",
    "        be n x n\n",
    "    B: array_like(float)\n",
    "        B is part of the state transition as described above. it should\n",
    "        be n x k\n",
    "    C: array_like(float), optional(default=None)\n",
    "        C is part of the state transition as described above. and\n",
    "        corresponds to the random variable today. if the model is\n",
    "        deterministic then C should take default value of None\n",
    "    beta: scalar(float), optional(default=None)\n",
    "        beta is the discount parameter\n",
    "    T: scalar(int), optional(default=None)\n",
    "        T is the number of periods in a finite horizon problem.\n",
    "    Rf: array_like(float), optional(default=None)\n",
    "        Rf is the final (in a finite horizon model) payoff(or cost)\n",
    "        matrix that correspinds with the control variableu and is n x n.\n",
    "        should be symmetric and non-negative definite\n",
    "        \n",
    "    attributes\n",
    "    ---------\n",
    "    Q, R, N, A, B, C, beta, T, Rf: see parameters\n",
    "    P: array_like(float)\n",
    "        P is part of the value function representation of V(x)=x'Px + d\n",
    "    d: array_like(float)\n",
    "        d is part of the value function representation of V(x)=x'Px + d\n",
    "    F: array_like(float)\n",
    "        F is the policy rule that determines the choice of control in\n",
    "        each period.\n",
    "    k, n, j: scalar(int)\n",
    "        the dimensions of the matrices as presented above\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, Q, R, A, B, C=None, N=None, beta=1, T=None, Rf=None):\n",
    "        #==make sure all matrices can be treated as 2D arrays==#\n",
    "        converter=lambda X: np.atleast_2d(np.asarray(X, dtype='float'))\n",
    "        self.A, self.B, self.Q, self.R, self.N=list(map(converter, (A, B, Q, R, N)))\n",
    "        #==record dimensions==#\n",
    "        self.k, self.n=self.Q.shape[0], self.R.shape[0]\n",
    "        \n",
    "        self.beta=beta\n",
    "        \n",
    "        if C is None:\n",
    "            #==if C not given, the model is deterministic, set C=0.==#\n",
    "            self.j=1\n",
    "            self.C=np.zeros((self.n, self.j))\n",
    "            \n",
    "        else:\n",
    "            self.C=converter(C)\n",
    "            self.j=self.C.shape[1]\n",
    "            \n",
    "        if N is None:\n",
    "            #== No cross product term in payoff. Set N=0.==#\n",
    "            self.N=np.zeros((self.k, self.n))\n",
    "            \n",
    "        if T:\n",
    "            #==model is finite horizon==#\n",
    "            self.T=T\n",
    "            self.Rf=np.asarray(Rf, dtype='float')\n",
    "            self.P=self.Rf\n",
    "            self.d=0\n",
    "        else:\n",
    "            self.P=None\n",
    "            self.d=None\n",
    "            self.T=None\n",
    "            \n",
    "        self.F=None\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return self.__str__()\n",
    "    \n",
    "    def __str__(self):\n",
    "        m=\"\"\"\\\n",
    "        Linear quadratic control system\n",
    "            -beta(discount parameter): {b}\n",
    "            -T(time horizon): {t}\n",
    "            -n(number of state variables): {n}\n",
    "            -k(number of control variables):{k}\n",
    "            -j(number of shocks): {j}\n",
    "        \"\"\"\n",
    "        t=\"infinite\" if self.T is None else self.T\n",
    "        return dedent(m.format(b=self.beta, n=self.n, k=self.k, j=self.j,\n",
    "                              t=t))\n",
    "    \n",
    "    def update_values(self):\n",
    "        \"\"\"\n",
    "        this method is for updating in the finite horizon case. it\n",
    "        shifts the current value function\n",
    "        \n",
    "            V_t{x}=x' P_t x + d_t\n",
    "            \n",
    "        and the optimal policy F_t one step *back* in time,\n",
    "        replacing the pair P_t and d_t with\n",
    "        P_{t-1} and d_{t-1}, and F_t with\n",
    "        F_{t-1}\n",
    "        \n",
    "        \"\"\"\n",
    "        #==simplify notation==#\n",
    "        Q, R, A, B, N, C=self.Q, self.R, self.A, self.B, self.N, self.C\n",
    "        P, d=self.P, self.d\n",
    "        #==some useful matrices==#\n",
    "        S1=Q+self.beta*dot(B.T, dot(P, B))\n",
    "        S2=self.beta*dot(B.T, dot(P, A))+N\n",
    "        S3=self.beta*dot(A.T, dot(P, A))\n",
    "        #==compute F as (Q+B'PB)^{-1}(beta B'PA + N)==#\n",
    "        self.F=solve(S1, S2)\n",
    "        #==shift P back in time one step==#\n",
    "        new_P=R-dot(S2.T, self.F) +S3\n",
    "        #==recalling that trace(AB)=trace(BA)==#\n",
    "        new_d=self.beta*(d + np.trace(dot(P, dot(C, C.T))))\n",
    "        #==set new state==#\n",
    "        self.P, self.d=new_P, new_d\n",
    "        \n",
    "    def stationary_values(self):\n",
    "        \"\"\"\n",
    "        computes the matrix P and scalar d that represent the value\n",
    "        function\n",
    "        \n",
    "            V(x)=x' P x + d\n",
    "        \n",
    "        in the infinite horizon case. also computes the control matrix\n",
    "        F from u = -Fx\n",
    "        \n",
    "        returns\n",
    "        ----------\n",
    "        P: array_like(float)\n",
    "            P is part of the value function representation of \n",
    "            V(x)=xPx + d\n",
    "        F: array_like(float)\n",
    "            F is the policy rule that determines the choice of control\n",
    "            in each period.\n",
    "        d: array_like(float)\n",
    "            d is part of the value function representation of\n",
    "            V(x)=xPx+ d\n",
    "            \n",
    "        \"\"\"\n",
    "        #==simplify notation==#\n",
    "        Q, R, A, B, N, C=self.Q, self.R, self.A, self.B, self.N, self.C\n",
    "        \n",
    "        #==solve riccati equation, obtain P==#\n",
    "        A0, B0 =np.sqrt(self.beta)*A, np.sqrt(self.beta)*B\n",
    "        P=solve_discrete_riccati(A0, B0, R, Q, N)\n",
    "        \n",
    "        #==compute F==#\n",
    "        S1=Q+self.beta*dot(B.T, dot(P, B))\n",
    "        S2=self.beta*dot(B.T, dot(P, A))+N\n",
    "        F=solve(S1, S2)\n",
    "        \n",
    "        #==compute d==#\n",
    "        d=self.beta * np.trace(dot(P, dot(C, C.T)))/(1-self.beta)\n",
    "        \n",
    "        #==bind states and return values==#\n",
    "        self.P, self.F, self.d=P, F, d\n",
    "        \n",
    "        return P, F, d\n",
    "    \n",
    "    def compute_sequence(self, x0, ts_length=None):\n",
    "        \"\"\"\n",
    "        compute and return the optimal state and control sequences\n",
    "        \"\"\"\n",
    "        \n",
    "        #==simplify notation==#\n",
    "        A, B, C=self.A, self.B, self.C\n",
    "        \n",
    "        #==preliminaries, finite horizon case==#\n",
    "        if self.T:\n",
    "            T=self.T if not ts_length else min(ts_length, self.T)\n",
    "            self.P, self.d=self.Rf, 0\n",
    "            \n",
    "        #==preliminaries, infinite horizon case==#\n",
    "        else:\n",
    "            T=ts_length if ts_length else 100\n",
    "            self.stationary_values()\n",
    "            \n",
    "        #==set up initial condition and array to store paths==#\n",
    "        x0=np.asarray(x0)\n",
    "        x0=x0.reshape(self.n,1) #make sure x0 is a column vector\n",
    "        x_path =np.empty((self.n, T+1))\n",
    "        u_path=np.empty((self.k, T))\n",
    "        w_path=dot(C, np.random.randn(self.j, T+1))\n",
    "        \n",
    "        #==compute and record the sequence of policies==#\n",
    "        policies=[]\n",
    "        for t in range(T):\n",
    "            if self.T: #finite horizon case\n",
    "                self.update_values()\n",
    "            policies.append(self.F)\n",
    "            \n",
    "        #==use policy sequance to generate states and controls==#\n",
    "        F=policies.pop()\n",
    "        x_path[:,0]=x0.flatten()\n",
    "        u_path[:,0]=-dot(F, x0).flatten()\n",
    "        for t in range(1, T):\n",
    "            F =policies.pop()\n",
    "            Ax, Bu=dot(A, x_path[:, t-1]),dot(B, u_path[:, t-1])\n",
    "            x_path[:, t]=Ax+Bu+w_path[:, t]\n",
    "            u_path[:, t]=-dot(F, x_path[:, t])\n",
    "        Ax, Bu=dot(A, x_path[:, T-1]), dot(B, u_path[:, T-1])\n",
    "        x_path[:, T]=Ax+Bu+w_path[:, T]\n",
    "        \n",
    "        return x_path, u_path, w_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
